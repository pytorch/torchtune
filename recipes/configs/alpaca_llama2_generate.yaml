# Config alpaca_generate.py recipe
#
# To launch, run the following command from root:
#    tune alpaca_generate --config alpaca_llama2_generate --override model_checkpoint=<your_checkpoint_dir> tokenizer_checkpoint=<your_tokenizer_dir>

# Model arguments
model:
  _component_: torchtune.models.llama2.llama2_7b
model_checkpoint: /tmp/test-artifacts/llama2-7b-01242024

# Tokenizer arguments
tokenizer:
  _component_: torchtune.models.llama2.llama2_tokenizer
  path: /tmp/test-artifacts/tokenizer.model

# Generation arguments
instruction: "Answer the question."
input: "What is some cool music from the 1920s?"
max_gen_len: 64
