# Config for torchtune/_cli/eval.py
#
# To launch, run the following command from root torchtune directory:
#    tune custom_eval --config default_eval_config

# Model Arguments
model:
  _component_: torchtune.models.llama2.llama2_7b


model_checkpoint: /tmp/llama2/model.ckpt

# Tokenizer
tokenizer:
  _component_: torchtune.models.llama2.llama2_tokenizer
  path: /tmp/llama2/tokenizer.model

# Environment
device: cuda
seed: 217

# Dataset on which to evaluate
dataset:
  _component_: torchtune.datasets.build_dataset
  source: tatsu-lab/alpaca_eval
  tokenizer: $tokenizer
  template: instruct
  pad: True
  packing: False
