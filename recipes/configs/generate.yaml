# Config alpaca_generate.py recipe
#
# To launch, run the following command from root:
#    tune alpaca_generate \
#    --config generate \
#    model_checkpoint=<your_checkpoint_dir> \
#    tokenizer_checkpoint=<your_tokenizer_dir>

# Model arguments
model:
  _component_: torchtune.models.llama2.llama2_7b
model_checkpoint: /tmp/llama2_native

# Tokenizer arguments
tokenizer:
  _component_: torchtune.models.llama2.llama2_tokenizer
  path: /tmp/llama2/tokenizer.model

# Generation arguments
instruction: "Answer the question."
input: "What is some cool music from the 1920s?"
max_gen_len: 64
