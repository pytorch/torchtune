# Config for torchtune/_cli/eval.py
#
# To launch, run the following command from root:
#    tune eval --config torchtune/_cli/eval_configs/default_eval_config.yaml

# Model Arguments
model:
  _component_: torchtune.models.llama2.lora_llama2_7b
  lora_attn_modules: ['q_proj', 'v_proj']
  apply_lora_to_mlp: False
  apply_lora_to_output: False
  lora_rank: 8
  lora_alpha: 16

model_checkpoint: /tmp/llama2_native
lora_checkpoint: null

# Tokenizer
tokenizer:
  _component_: torchtune.models.llama2.llama2_tokenizer
  path: /tmp/llama2/tokenizer.model


# Environment
device: cuda
seed: 217

# EleutherAI specific eval args
tasks: ["hellaswag"]
limit: null
